{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FYS-STK4155 - Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compare the linear regression methods Ordinary Least Squares (OLS) method, Ridge regression and Lasso regression. To do this we are going to fit them to the Franke function and terrain data and evaluate them using the resampling methods bootstrap and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1) #Comment this out to get random results\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are starting off by fitting the Franke function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "f(x,y) &= \\frac{3}{4}\\exp{\\left(-\\frac{(9x-2)^2}{4} - \\frac{(9y-2)^2}{4}\\right)}+\\frac{3}{4}\\exp{\\left(-\\frac{(9x+1)^2}{49}- \\frac{(9y+1)}{10}\\right)} \\\\\n",
    "&+\\frac{1}{2}\\exp{\\left(-\\frac{(9x-7)^2}{4} - \\frac{(9y-3)^2}{4}\\right)} -\\frac{1}{5}\\exp{\\left(-(9x-4)^2 - (9y-7)^2\\right) }.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def franke(x, y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Franke Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any linear regression, we should plot the franke function to make sure the function is defined properly and that the function is suited to a polynomial fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data\n",
    "x = np.linspace(0, 1, 20)\n",
    "y = np.linspace(0, 1, 20)\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = franke(x, y)\n",
    "\n",
    "# Plot the surface\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the axes\n",
    "ax.set_zlim(-0.10, 1.40)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "# Add a color bar which maps values to colors\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.savefig(\"Figures/franke\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to set up data for fitting many times this project, so we should define functions for generating data, creating a design matrix, and scaling the design matrix.\n",
    "\n",
    "We are going to use polynomials of x and y to fit the data. If we want to use a fifth order polynomial, the possible terms in the polynomial are multiples of the following terms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& 1\\;\\;\\;\\;\\;\\;\\;   x\\;\\;\\;\\;\\;\\;\\;    x^2\\;\\;\\;\\;\\;\\;\\;   x^3\\;\\;\\;\\;\\;\\;\\;   x^4\\;\\;\\;\\;\\;\\;\\;  x^5 \\\\\n",
    "& y\\;\\;\\;\\;\\;\\;   yx\\;\\;\\;\\;\\;  yx^2\\;\\;\\;\\;\\;  yx^3\\;\\;\\;\\;\\;  yx^4 \\\\\n",
    "& y^2\\;\\;\\;  y^2x\\;\\;\\;\\;  y^2x^2\\;\\;\\;  y^2x^3 \\\\\n",
    "& y^3\\;\\;\\;  y^3x\\;\\;\\;\\;  y^3x^2 \\\\\n",
    "& y^4\\;\\;\\;  y^4x \\\\\n",
    "& y^5 \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the order of the polynomial, we get a different number of parameters for the fit. The number of parameters p is given by the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pval(order):\n",
    "    return int((order + 1) * (order + 2) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`designMatrix()` creates the design matrix by evaluating all of these terms in the polynomial as a function of input vectors x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit #makes the function faster\n",
    "def designMatrix(x, y, order):\n",
    "    n = x.size\n",
    "    p = int((order + 1) * (order + 2) / 2) # number of columns in X (can't use the function pval() due to @jit)\n",
    "    X = np.zeros((n, p))\n",
    "    feature = 0\n",
    "    for x_power in range(order + 1):\n",
    "        for y_power in range(order - x_power + 1):\n",
    "            X[:, feature] = x**x_power * y**y_power\n",
    "            feature += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data()` generates datapoints from the franke function with noise at random points (x, y), and returns the design matrix and z-values. We found that n = 100 is few enough datapoints to see overfitting, so we will use 100 datapoints for the franke function for the rest of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # datapoints\n",
    "def data(n, order):\n",
    "    x = np.random.rand(n) #an array of n unordered uniform random numbers from 0 to 1\n",
    "    y = np.random.rand(n)\n",
    "    noise = np.random.randn(n) / 10\n",
    "    \n",
    "    z = franke(x, y) + noise\n",
    "    X = designMatrix(x, y, order)\n",
    "    \n",
    "    return X, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scale()` scales training and test data according to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X_train, X_test):\n",
    "    scaler = StandardScaler() #subtracts mean from each feature and divides by the standard deviation\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_train[:, 0] = 1 # scaling removed the intercept terms\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test[:, 0] = 1\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for finding the optimal parameters with our three regression methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(X, z, lmda=None, p=None):\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ z\n",
    "    return beta\n",
    "\n",
    "def ridge(X, z, lmda, p):\n",
    "    beta = np.linalg.inv(X.T @ X + lmda * np.eye(p)) @ X.T @ z\n",
    "    return beta\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def lasso(X, z, lmda, p):\n",
    "    clf = skl.Lasso(lmda)\n",
    "    clf.fit(X,z)\n",
    "    return clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a): Ordinary Least Square (OLS) on the Franke function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the data using OLS to find the optimal coefficients of a fifth order polynomial in x and y. We find the mean squared error on the training and test data, together with the R2-score and the confidence intervals of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of data\n",
    "order = 5 # max order of polynomials\n",
    "X, z = data(n, order)\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2)\n",
    "X_train, X_test = scale(X_train, X_test)\n",
    "# OLS regression\n",
    "beta = OLS(X_train, z_train)\n",
    "# Evaluation of model\n",
    "z_mdl = X_test @ beta\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(X_train @ beta, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "\n",
    "print(f\"R2 score on training data = {r2_score(X_train @ beta, z_train):.4f}\")\n",
    "print(f\"R2 score = {r2_score(z_mdl, z_test):.4f}\")\n",
    "\n",
    "print(\"Coefficients with 95% confidence intervals:\")\n",
    "betaVar = np.linalg.inv(X_train.T @ X_train)\n",
    "for i in range(pval(order)):\n",
    "    std = betaVar[i, i]**0.5 * 0.01 #variance of noise is 0.01\n",
    "    print(f\"B_{i+1} = {beta[i]:.2f} +- {1.96 * std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b): Bias-variance trade-off and resampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we analyze the bias-variance tradeoff with bootstrap resampling, we compare training and test MSE as a function of model complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 7\n",
    "p_arr = [pval(i) for i in range(max_order + 1)]\n",
    "\n",
    "training_mse = np.zeros(len(p_arr))\n",
    "test_mse = np.zeros(len(p_arr))\n",
    "\n",
    "for i in range(max_order+1):\n",
    "    X, z = data(n, i)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2)\n",
    "    X_train, X_test = scale(X_train, X_test)\n",
    "    beta = OLS(X_train, z_train)\n",
    "    # Evaluation of model\n",
    "    training_mse[i] = mean_squared_error(X_train @ beta, z_train)\n",
    "    test_mse[i] = mean_squared_error(X_test @ beta, z_test)\n",
    "\n",
    "plt.plot(p_arr, training_mse, label='Training MSE')\n",
    "plt.plot(p_arr, test_mse, label='Test MSE')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Model Complexity\")\n",
    "plt.ylabel(\"Prediction Error\")\n",
    "plt.title(\"OLS Training vs. Test MSE for different model complexity\")\n",
    "plt.savefig(\"Figures/trainingvtest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more robust way to evaluate the MSE of a model is to use resampling techniques. We first implement bootstrap resampling. `bootBiasVar()` splits and scales the data X and z, does `n_bootstraps` bootstraps on the training data, and returns the mean squared error, bias and variance of the model using a polynomial of a given order `order` and regression function `reg_func`. We will use this function throughout this notebook to analyze the bias-variance tradeoff for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootBiasVar(n_boostraps, X, z, order, reg_func, lmda=0):\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2)\n",
    "    X_train, X_test = scale(X_train, X_test)\n",
    "    \n",
    "    z_pred = np.empty((n_boostraps, z_test.size))\n",
    "    for i in range(n_boostraps):\n",
    "        X_, z_ = resample(X_train, z_train)\n",
    "        z_pred[i] = X_test @ reg_func(X_, z_, lmda, pval(order))\n",
    "\n",
    "    mse = np.mean( np.mean((z_test - z_pred)**2, axis=0, keepdims=True) )\n",
    "    bias = np.mean( (z_test - np.mean(z_pred, axis=0, keepdims=True))**2 )\n",
    "    var = np.mean( np.var(z_pred, axis=0, keepdims=True) )\n",
    "    \n",
    "    return mse, bias, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance tradeoff for polynomial order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boostraps = 20\n",
    "max_order = 7\n",
    "p_arr = [pval(i) for i in range(max_order + 1)]\n",
    "\n",
    "mse_arr = np.zeros(len(p_arr))\n",
    "bias_arr = np.zeros(len(p_arr))\n",
    "var_arr = np.zeros(len(p_arr))\n",
    "for j in range(max_order+1):\n",
    "    X, z = data(n, j)\n",
    "    mse_arr[j], bias_arr[j], var_arr[j] = bootBiasVar(n_boostraps, X, z, j, OLS)\n",
    "\n",
    "plt.plot(p_arr, mse_arr, label='MSE')\n",
    "plt.plot(p_arr, bias_arr, label='bias')\n",
    "plt.plot(p_arr, var_arr, label='variance')\n",
    "plt.xlabel(\"Model Complexity\")\n",
    "plt.legend()\n",
    "plt.title(\"OLS Bias variance tradeoff for model complexity\")\n",
    "plt.savefig(\"Figures/OLSbiasvar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance tradeoff for the number of datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boostraps = 20\n",
    "order = 5\n",
    "n_arr = np.linspace(50, 200, 10, dtype=int)\n",
    "\n",
    "mse_arr = np.zeros(len(n_arr))\n",
    "bias_arr = np.zeros(len(n_arr))\n",
    "var_arr = np.zeros(len(n_arr))\n",
    "for j, n in enumerate(n_arr):\n",
    "    X, z = data(n, order)\n",
    "    mse_arr[j], bias_arr[j], var_arr[j] = bootBiasVar(n_boostraps, X, z, order, OLS)\n",
    "\n",
    "plt.plot(n_arr, mse_arr, label='MSE')\n",
    "plt.plot(n_arr, bias_arr, label='bias')\n",
    "plt.plot(n_arr, var_arr, label='variance')\n",
    "plt.xlabel('Datapoints')\n",
    "plt.legend()\n",
    "plt.title(\"OLS Bias variance tradeoff for number of datapoints\")\n",
    "plt.savefig(\"Figures/OLSdatapoints\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c): Cross-validation as resampling techniques, adding more complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, k):\n",
    "    n = len(data)\n",
    "    fold_size = n // k #standard fold size, will be one larger if we need to get rid of extra elements\n",
    "    test_start = 0\n",
    "    extra = n % k #the first extra folds need one more element\n",
    "    \n",
    "    fold_indexes = []\n",
    "    for i in range(k):\n",
    "        if extra > 0:\n",
    "            test_size = fold_size + 1\n",
    "            extra -= 1\n",
    "        else:\n",
    "            test_size = fold_size\n",
    "        training_size = n - test_size\n",
    "        test_stop = test_start + test_size\n",
    "        \n",
    "        training_indexes = np.zeros(training_size, dtype=int)\n",
    "        training_indexes[:test_start] = np.array(range(0, test_start)) #before testing\n",
    "        training_indexes[test_start:] = np.array(range(test_stop, n)) #after testing\n",
    " \n",
    "        testing_indexes = np.array(range(test_start, test_stop))\n",
    "\n",
    "        fold_indexes.append([training_indexes, testing_indexes])\n",
    "        test_start += test_size\n",
    "        \n",
    "    return fold_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_mse(X, z, order, k, reg_func, lmda=0):\n",
    "    MSE = 0\n",
    "    for train_inds, test_inds in split(X, k):\n",
    "        X_train = X[train_inds]\n",
    "        X_test = X[test_inds]\n",
    "        X_train, X_test = scale(X_train, X_test)\n",
    "\n",
    "        z_train = z[train_inds]\n",
    "        z_test = z[test_inds]\n",
    "\n",
    "        beta = reg_func(X_train, z_train, lmda, pval(order))\n",
    "        z_mdl = X_test @ beta\n",
    "        MSE += mean_squared_error(z_mdl, z_test) / k\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 6\n",
    "p_arr = [pval(i) for i in range(max_order + 1)]\n",
    "k = 10\n",
    "mse_arr = np.zeros(len(p_arr))\n",
    "\n",
    "n_boostraps = 10\n",
    "bootstrap_mse_arr = np.zeros(len(p_arr))\n",
    "\n",
    "for j in range(max_order + 1):\n",
    "    X, z = data(n, j)\n",
    "    mse_arr[j] = CV_mse(X, z, j, k, OLS)\n",
    "    bootstrap_mse_arr[j] = bootBiasVar(n_boostraps, X, z, j, OLS)[0]\n",
    "\n",
    "\n",
    "plt.plot(p_arr, mse_arr, label=\"CV\")\n",
    "plt.plot(p_arr, bootstrap_mse_arr, label=\"Bootstrap\")\n",
    "plt.title('MSE for different degrees of freedom')\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title(\"OLS MSE for different model complexity, CV and Bootstrap\")\n",
    "plt.savefig(\"Figures/OLScvboot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part d): Ridge Regression on the Franke function with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap analysis for different values of lambda\n",
    "lmda = np.logspace(-9,3,10)\n",
    "n_boostraps = 20\n",
    "order = 8\n",
    "\n",
    "mse_arr = np.zeros(len(lmda))\n",
    "bias_arr = np.zeros(len(lmda))\n",
    "var_arr = np.zeros(len(lmda))\n",
    "\n",
    "for i,l in enumerate(lmda):\n",
    "    X, z = data(n, order)\n",
    "    mse_arr[i], bias_arr[i], var_arr[i] = bootBiasVar(n_boostraps, X, z, order, ridge,l)\n",
    "\n",
    "plt.plot(lmda, mse_arr, label='MSE')\n",
    "plt.plot(lmda, bias_arr, label='bias')\n",
    "plt.plot(lmda, var_arr, label='variance')\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.title('Bias-Variance trade-off for Ridge regression with bootstrap')\n",
    "plt.savefig(\"Figures/ridgebiasvar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part e): Lasso Regression on the Franke function with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap analysis for different values of lambda\n",
    "lmda = np.logspace(-9,3,10)\n",
    "n_boostraps = 20\n",
    "order = 8\n",
    "\n",
    "mse_arr = np.zeros(len(lmda))\n",
    "bias_arr = np.zeros(len(lmda))\n",
    "var_arr = np.zeros(len(lmda))\n",
    "\n",
    "for i,l in enumerate(lmda):\n",
    "    X, z = data(n, order)\n",
    "    mse_arr[i], bias_arr[i], var_arr[i] = bootBiasVar(n_boostraps, X, z, order, lasso,l)\n",
    "\n",
    "plt.plot(lmda, mse_arr, label='MSE', )\n",
    "plt.plot(lmda, bias_arr, label='bias')\n",
    "plt.plot(lmda, var_arr, label='variance')\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.title('Bias-Variance trade-off for Lasso regression with bootstrap')\n",
    "plt.savefig(\"Figures/lassobiasvar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part d) + e): Ridge and Lasso Regression on the Franke function with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for different values of lambda\n",
    "lmda = np.logspace(-9,3,10)\n",
    "order = 8\n",
    "ridge_mse = np.zeros(len(lmda))\n",
    "lasso_mse = np.zeros(len(lmda))\n",
    "k = 10\n",
    "\n",
    "for i,l in enumerate(lmda):\n",
    "    X, z = data(n, order)\n",
    "    ridge_mse[i] = CV_mse(X, z, order, k, ridge,l)\n",
    "    lasso_mse[i] = CV_mse(X, z, order, k, lasso,l)\n",
    "\n",
    "ols_mse = CV_mse(X, z, order, k, OLS)\n",
    "plt.plot([lmda[0], lmda[-1]], [ols_mse, ols_mse], label=\"OLS\")\n",
    "plt.plot(lmda, ridge_mse, label=\"Ridge\")\n",
    "plt.plot(lmda, lasso_mse, label=\"Lasso\")\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.ylabel('MSE')\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.title(r'CV: MSE for different $\\lambda$ using different methods')\n",
    "plt.savefig(\"Figures/cvmseall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for different values of lambda\n",
    "lmda = 1E-5\n",
    "k = 10\n",
    "\n",
    "max_order = 10\n",
    "p_arr = [pval(i) for i in range(max_order + 1)]\n",
    "\n",
    "ridge_mse = np.zeros(len(p_arr))\n",
    "lasso_mse = np.zeros(len(p_arr))\n",
    "ols_mse = np.zeros(len(p_arr))\n",
    "\n",
    "for i in range(max_order+1):\n",
    "    X, z = data(n, i)\n",
    "    ols_mse[i] = CV_mse(X, z, i, k, OLS)\n",
    "    ridge_mse[i] = CV_mse(X, z, i, k, ridge, lmda)\n",
    "    lasso_mse[i] = CV_mse(X, z, i, k, lasso, lmda)\n",
    "\n",
    "plt.plot(p_arr, ols_mse, label=\"OLS\")\n",
    "plt.plot(p_arr, ridge_mse, label=\"Ridge\")\n",
    "plt.plot(p_arr, lasso_mse, label=\"Lasso\")\n",
    "plt.xlabel(\"Model complexity\")\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title(r'CV: MSE for different model complexity using different methods')\n",
    "plt.savefig(\"Figures/cvmsealln\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part f): Introducing real data and preparing the data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# Load the terrain\n",
    "terrain = imread('denver.tif')\n",
    "# Show the terrain\n",
    "plt.figure(figsize=(4,8))\n",
    "plt.title('Terrain over Colorado')\n",
    "plt.imshow(terrain, cmap='gray')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "x1 = 1200\n",
    "x2 = 1250\n",
    "y1 = 1500\n",
    "y2 = 1550\n",
    "plt.plot([x1,x2], [y1, y1])\n",
    "plt.plot([x1,x2], [y2, y2])\n",
    "plt.plot([x1,x1], [y1, y2])\n",
    "plt.plot([x2,x2], [y1, y2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The part of the data we will use for the analysis\n",
    "z_grid = terrain[y1:y2, x1:x2]\n",
    "# x and y values corresponding to z values\n",
    "x_grid = np.linspace(0, 1, np.shape(z_grid)[1])\n",
    "y_grid = np.linspace(0, 1, np.shape(z_grid)[0])\n",
    "x_grid, y_grid = np.meshgrid(x_grid, y_grid)\n",
    "# Arrays used for analysis\n",
    "z = z_grid.ravel()\n",
    "x = x_grid.ravel()\n",
    "y = y_grid.ravel()\n",
    "z, x, y = shuffle(z, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the surface\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(x_grid, y_grid, z_grid, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the axes\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "# Add a color bar which maps values to colors\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.view_init(30, 30)\n",
    "plt.savefig(\"Figures/terrain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part g) OLS, Ridge and Lasso regression with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [8, 15, 16, 17, 18, 19]\n",
    "lambdas = [0, 1E-9, 1E-8, 1E-7]\n",
    "p_arr = [pval(i) for i in orders]\n",
    "\n",
    "k = 10 #numbers of folds in cross validation\n",
    "\n",
    "cv_OLS = np.zeros(len(orders))\n",
    "cv_Ridge = np.zeros((len(orders), len(lambdas)))\n",
    "cv_Lasso = np.zeros((len(orders), len(lambdas)))\n",
    "\n",
    "for i, order in enumerate(orders):\n",
    "    X = designMatrix(x, y, order)\n",
    "    \n",
    "    cv_OLS[i] = CV_mse(X, z, order, k, OLS)\n",
    "    for j, lmda in enumerate(lambdas):\n",
    "        cv_Ridge[i][j] = CV_mse(X, z, order, k, ridge, lmda)\n",
    "        #if lmda != 0:\n",
    "         #   cv_Lasso[i][j] = CV_mse(X, z, order, k, lasso, lmda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(cv_Ridge))\n",
    "\n",
    "optimalindex = np.unravel_index(cv_Ridge.argmin(), cv_Ridge.shape)\n",
    "order_opt = orders[optimalindex[0]]\n",
    "lmda_opt = lambdas[optimalindex[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = designMatrix(x, y, order_opt)\n",
    "beta = ridge(X, z, lmda_opt, pval(order_opt))\n",
    "\n",
    "x_p = np.linspace(0, 1, 100)\n",
    "y_p = np.linspace(0, 1, 100)\n",
    "x_p, y_p = np.meshgrid(x_p, y_p)\n",
    "\n",
    "x_p = x_p.ravel()\n",
    "y_p = y_p.ravel()\n",
    "X_p = designMatrix(x_p, y_p, order)\n",
    "z_p = X_p @ beta\n",
    "\n",
    "x_p = x_p.reshape((100, 100))\n",
    "y_p = y_p.reshape((100, 100))\n",
    "z_p = np.array(z_p).reshape((100, 100))\n",
    "\n",
    "# Plot the surface\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(x_p, y_p, z_p, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the axes\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "# Add a color bar which maps values to colors\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.view_init(30, 30)\n",
    "plt.savefig(\"Figures/terrainfit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
