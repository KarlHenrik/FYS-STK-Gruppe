{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from linearReg import LinearReg\n",
    "from gdOptimizers import GDOptimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def franke(x, y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(n = 100):\n",
    "    x = np.random.rand(n) #an array of n unordered uniform random numbers from 0 to 1\n",
    "    y = np.random.rand(n)\n",
    "    xy = np.column_stack((x, y))\n",
    "    \n",
    "    noise = np.random.randn(n) / 10\n",
    "    z = franke(x, y) + noise\n",
    "    return xy, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy, z = data()\n",
    "xy_train, xy_test, z_train, z_test = train_test_split(xy, z, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FFNN import FFNN\n",
    "\n",
    "nn = FFNN(inputs = 2)\n",
    "nn.addLayer(neurons = 5, activation = \"sigmoid\")\n",
    "nn.addLayer(neurons = 5, activation = \"sigmoid\")\n",
    "nn.addLayer(neurons = 1, activation = \"sigmoid\")\n",
    "\n",
    "nn.feedForward(xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.array([[[1,2], [3,4]]])\n",
    "print(th)\n",
    "th = th.tolist()\n",
    "th.append([[5,6], [7,8]])\n",
    "print(th)\n",
    "print(th[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(order = 3, lmda = 1E-5)\n",
    "sgd = GDOptimizers(learning_rate = 0.01, epochs = 1000, batch_size = 10, optimizer = \"SGD\")\n",
    "z_train_mdl = model.fit(xy_train, z_train, sgd)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(order = 3, lmda = 1E-5)\n",
    "momentum = GDOptimizers(learning_rate = 0.01, epochs = 1000, batch_size = 10, optimizer = \"momentum\", alpha=0.5)\n",
    "z_train_mdl = model.fit(xy_train, z_train, momentum)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of grid search\n",
    "# uses seaborn heatmap, you can also do this with matplotlib imshow\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "eta_vals = np.logspace(-4, -2, 6)\n",
    "lmbd_vals = np.logspace(-5, 1, 7)\n",
    "train_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "test_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmda in enumerate(lmbd_vals):\n",
    "        model = LinearReg(order = 3, lmda = lmda)\n",
    "        sgd = GDOptimizers(learning_rate = eta, epochs = 100, batch_size = 10, optimizer = \"SGD\")\n",
    "        \n",
    "        z_train_mdl = model.fit(xy_train, z_train, sgd)\n",
    "        z_mdl = model.predict(xy_test)\n",
    "\n",
    "        train_mse[i][j] = mean_squared_error(z_train_mdl, z_train)\n",
    "        test_mse[i][j] = mean_squared_error(z_mdl, z_test)\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(train_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Training MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Test MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
