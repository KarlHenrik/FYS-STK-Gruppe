{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from linearReg import LinearReg\n",
    "from gdOptimizers import GDOptimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(64, 10)\n",
    "bias = np.zeros([10,1]) + 0.01\n",
    "theta = np.array([w, bias], dtype = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def franke(x, y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(n = 100):\n",
    "    x = np.random.rand(n) #an array of n unordered uniform random numbers from 0 to 1\n",
    "    y = np.random.rand(n)\n",
    "    xy = np.column_stack((x, y))\n",
    "    \n",
    "    noise = np.random.randn(n) / 10\n",
    "    z = np.array([franke(x, y) + noise]).T\n",
    "    return xy, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy, z = data(100)\n",
    "xy_train, xy_test, z_train, z_test = train_test_split(xy, z, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FFNN import FFNN\n",
    "\n",
    "nn = FFNN(inputs = 2)\n",
    "nn.addLayer(neurons = 5, activation = \"sigmoid\")\n",
    "nn.addLayer(neurons = 1, activation = \"linear\")\n",
    "\n",
    "sgd = GDOptimizers(learning_rate = 0.00005, epochs = 1000, batch_size = 10, optimizer = \"momentum\")\n",
    "nn.compile(loss=\"mse\", optimizer=sgd, lmda = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mdl = nn.predict(xy_test)\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "z_mdl = nn.predict(xy_train)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_mdl, z_train):.4f}\")\n",
    "\n",
    "z_train_mdl = nn.fit(xy_train, z_train)\n",
    "z_mdl = nn.predict(xy_test)\n",
    "\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of grid search\n",
    "# uses seaborn heatmap, you can also do this with matplotlib imshow\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "eta_vals = np.logspace(-8, -4, 8)\n",
    "lmbd_vals = np.logspace(-5, -1, 7)\n",
    "train_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "test_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmda in enumerate(lmbd_vals):\n",
    "        nn = FFNN(inputs = 2)\n",
    "        nn.addLayer(neurons = 5, activation = \"sigmoid\")\n",
    "        nn.addLayer(neurons = 1, activation = \"linear\")\n",
    "\n",
    "        sgd = GDOptimizers(learning_rate = eta, epochs = 1000, batch_size = 10, optimizer = \"SGD\")\n",
    "        nn.compile(loss=\"mse\", optimizer=sgd, lmda = lmda)\n",
    "        \n",
    "        z_train_mdl = nn.fit(xy_train, z_train)\n",
    "        z_mdl = nn.predict(xy_test)\n",
    "\n",
    "        train_mse[i][j] = mean_squared_error(z_train_mdl, z_train)\n",
    "        test_mse[i][j] = mean_squared_error(z_mdl, z_test)\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(train_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Training MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Test MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(order = 3, lmda = 1E-5)\n",
    "sgd = GDOptimizers(learning_rate = 0.01, epochs = 1000, batch_size = 10, optimizer = \"SGD\")\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error before fit = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "\n",
    "z_train_mdl = model.fit(xy_train, z_train, sgd)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(order = 3, lmda = 1E-5)\n",
    "momentum = GDOptimizers(learning_rate = 0.01, epochs = 1000, batch_size = 10, optimizer = \"momentum\", alpha=0.5)\n",
    "z_train_mdl = model.fit(xy_train, z_train, momentum)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of grid search\n",
    "# uses seaborn heatmap, you can also do this with matplotlib imshow\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "eta_vals = np.logspace(-4, -2, 6)\n",
    "lmbd_vals = np.logspace(-5, 1, 7)\n",
    "train_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "test_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmda in enumerate(lmbd_vals):\n",
    "        model = LinearReg(order = 3, lmda = lmda)\n",
    "        sgd = GDOptimizers(learning_rate = eta, epochs = 100, batch_size = 10, optimizer = \"SGD\")\n",
    "        \n",
    "        z_train_mdl = model.fit(xy_train, z_train, sgd)\n",
    "        z_mdl = model.predict(xy_test)\n",
    "\n",
    "        train_mse[i][j] = mean_squared_error(z_train_mdl, z_train)\n",
    "        test_mse[i][j] = mean_squared_error(z_mdl, z_test)\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(train_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Training MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Test MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential      #This allows appending layers to existing models\n",
    "from tensorflow.keras.layers import Dense           #This allows defining the characteristics of a particular layer\n",
    "from tensorflow.keras import optimizers             #This allows using whichever optimiser we want (sgd,adam,RMSprop)\n",
    "from tensorflow.keras import regularizers           #This allows using whichever regularizer we want (l1,l2,l1_l2)\n",
    "from tensorflow.keras.utils import to_categorical   #This allows using categorical cross entropy as the cost function\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "eta = 0.001\n",
    "sgd = optimizers.SGD(lr=eta)\n",
    "model.compile(loss='mse', optimizer=sgd, metrics=['mse'])\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error before fit = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "\n",
    "model.fit(xy_train, z_train, epochs=1000, batch_size=10, verbose=0)\n",
    "#scores = model.evaluate(xy_test, z_test)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
