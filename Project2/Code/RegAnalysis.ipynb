{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from linearReg import LinearReg\n",
    "from gdOptimizers import GDOptimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(64, 10)\n",
    "bias = np.zeros([10,1]) + 0.01\n",
    "theta = np.array([w, bias], dtype = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def franke(x, y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(n = 100):\n",
    "    x = np.random.rand(n) #an array of n unordered uniform random numbers from 0 to 1\n",
    "    y = np.random.rand(n)\n",
    "    xy = np.column_stack((x, y))\n",
    "    \n",
    "    noise = np.random.randn(n) / 10\n",
    "    z = np.array([franke(x, y) + noise]).T\n",
    "    return xy, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy, z = data(100)\n",
    "xy_train, xy_test, z_train, z_test = train_test_split(xy, z, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FFNN' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6b693f0e5486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGDOptimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'FFNN' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "from FFNN import FFNN\n",
    "\n",
    "nn = FFNN(inputs = 2)\n",
    "nn.addLayer(neurons = 5, activation = \"sigmoid\")\n",
    "nn.addLayer(neurons = 1, activation = \"linear\")\n",
    "\n",
    "sgd = GDOptimizers(learning_rate = 0.00005, epochs = 1000, batch_size = 10, optimizer = \"momentum\")\n",
    "nn.compile(loss=\"mse\", optimizer=sgd, lmda = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-65508596850d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mz_mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean squared error on training data = {mean_squared_error(z_mdl, z_train):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/FYS-STK-Gruppe/Project2/Code/FFNN.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, a_in)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_feedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma_in\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# _as[i] comes into layer i. is the output of layer i - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/FYS-STK-Gruppe/Project2/Code/FFNN.py\u001b[0m in \u001b[0;36m_feedForward\u001b[0;34m(self, a_in)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported activation function.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ADD SPECIFICS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "z_mdl = nn.predict(xy_test)\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "z_mdl = nn.predict(xy_train)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_mdl, z_train):.4f}\")\n",
    "\n",
    "z_train_mdl = nn.fit(xy_train, z_train)\n",
    "z_mdl = nn.predict(xy_test)\n",
    "\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FFNN' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-74f381a97c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGDOptimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mz_train_mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FFNN' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "# visual representation of grid search\n",
    "# uses seaborn heatmap, you can also do this with matplotlib imshow\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "eta_vals = np.logspace(-8, -4, 8)\n",
    "lmbd_vals = np.logspace(-5, -1, 7)\n",
    "train_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "test_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmda in enumerate(lmbd_vals):\n",
    "        nn = FFNN(inputs = 2)\n",
    "        nn.addLayer(neurons = 5, activation = \"sigmoid\")\n",
    "        nn.addLayer(neurons = 1, activation = \"linear\")\n",
    "\n",
    "        sgd = GDOptimizers(learning_rate = eta, epochs = 1000, batch_size = 10, optimizer = \"SGD\")\n",
    "        nn.compile(loss=\"mse\", optimizer=sgd, lmda = lmda)\n",
    "        \n",
    "        z_train_mdl = nn.fit(xy_train, z_train)\n",
    "        z_mdl = nn.predict(xy_test)\n",
    "\n",
    "        train_mse[i][j] = mean_squared_error(z_train_mdl, z_train)\n",
    "        test_mse[i][j] = mean_squared_error(z_mdl, z_test)\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(train_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Training MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Test MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(order = 3, lmda = 1E-5)\n",
    "sgd = GDOptimizers(learning_rate = 0.01, epochs = 1000, batch_size = 10, optimizer = \"SGD\")\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error before fit = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "\n",
    "z_train_mdl = model.fit(xy_train, z_train, sgd)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(order = 3, lmda = 1E-5)\n",
    "momentum = GDOptimizers(learning_rate = 0.01, epochs = 1000, batch_size = 10, optimizer = \"momentum\", alpha=0.5)\n",
    "z_train_mdl = model.fit(xy_train, z_train, momentum)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error on training data = {mean_squared_error(z_train_mdl, z_train):.4f}\")\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of grid search\n",
    "# uses seaborn heatmap, you can also do this with matplotlib imshow\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "eta_vals = np.logspace(-4, -2, 6)\n",
    "lmbd_vals = np.logspace(-5, 1, 7)\n",
    "train_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "test_mse = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmda in enumerate(lmbd_vals):\n",
    "        model = LinearReg(order = 3, lmda = lmda)\n",
    "        sgd = GDOptimizers(learning_rate = eta, epochs = 100, batch_size = 10, optimizer = \"SGD\")\n",
    "        \n",
    "        z_train_mdl = model.fit(xy_train, z_train, sgd)\n",
    "        z_mdl = model.predict(xy_test)\n",
    "\n",
    "        train_mse[i][j] = mean_squared_error(z_train_mdl, z_train)\n",
    "        test_mse[i][j] = mean_squared_error(z_mdl, z_test)\n",
    "\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(train_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Training MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(test_mse, annot=True, ax=ax, cmap=\"viridis_r\", xticklabels=np.log10(lmbd_vals), yticklabels=np.log10(eta_vals))\n",
    "ax.set_title(\"Test MSE\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-71c0a58920ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m      \u001b[0;31m#This allows appending layers to existing models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m           \u001b[0;31m#This allows defining the characteristics of a particular layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m             \u001b[0;31m#This allows using whichever optimiser we want (sgd,adam,RMSprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m           \u001b[0;31m#This allows using whichever regularizer we want (l1,l2,l1_l2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential      #This allows appending layers to existing models\n",
    "from tensorflow.keras.layers import Dense           #This allows defining the characteristics of a particular layer\n",
    "from tensorflow.keras import optimizers             #This allows using whichever optimiser we want (sgd,adam,RMSprop)\n",
    "from tensorflow.keras import regularizers           #This allows using whichever regularizer we want (l1,l2,l1_l2)\n",
    "from tensorflow.keras.utils import to_categorical   #This allows using categorical cross entropy as the cost function\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-99a5c7ed2c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "eta = 0.001\n",
    "sgd = optimizers.SGD(lr=eta)\n",
    "model.compile(loss='mse', optimizer=sgd, metrics=['mse'])\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error before fit = {mean_squared_error(z_mdl, z_test):.4f}\")\n",
    "\n",
    "model.fit(xy_train, z_train, epochs=1000, batch_size=10, verbose=0)\n",
    "#scores = model.evaluate(xy_test, z_test)\n",
    "\n",
    "z_mdl = model.predict(xy_test)\n",
    "print(f\"Mean squared error = {mean_squared_error(z_mdl, z_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
